# 实验记录



## 2024年7月3日

### 1. 关键词

​	EEG时间序列建模、自回归层结构液态机

### 2. 归档文件

1. 源代码： [SNN_pkg_07031834.tar.gz](src_files/history/SNN_pkg_07031834.tar.gz)
2. STDP液态机模型及实验数据： [STDP_model_07031659.tar.gz](model/STDP/EEG/STDP_model_07031659.tar.gz) 
3. 回归分类器及实验数据： [Reg_model_07031936.tar.gz](model/Regression/Reg_model_07031936.tar.gz) 

### 3. 实验目的

​	完成StdpModel.py和Regression.py代码的修正，保证其正常工作，初步研究当前架构是否有特征提取能力。

### 4. 实验结果

​	STDP及Regression两部分代码已全部跑通。

​	编码上，对DEAP脑电数据集取前14个通道（未必是适用于情感计算的通道），并以0为界，编码为脉冲序列。液态机方面，按原先设计，设置三个自连接突触，导致训练时三个LIF层神经元脉冲发放率均为100%；遂去掉前两层的自回归突触，保留第三层，成功使脉冲发放稀疏化。经59条相互独立的数据处理后，各层$C_l$值收敛至$10^{-5}$以下。

​	训练过程中，$C_l$值变化如下图：

![cl](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/cl.jpg)

​	脉冲发放率变化如下图（仅对一条数据最后一个时间步所诱发的脉冲发放进行采样）：

![firing_rate](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/firing_rate.jpg)

​	随机选取三条相互独立的数据，记录每个时间步所诱发的脉冲发放率。时间步7800后，脉冲发放率变化如下图所示：

![3_sample_test](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/3_sample_test.jpg)

​	可以看到，数据间脉冲发放有较大差异性，这说明该液态机可能实现了特征提取。

​	但问题在于，由训练期间脉冲发放率变化图所示，每条数据最后一个时间步都会导致最后一层脉冲发放。因此，在回归时，改设最后一层LIF的阈值尽可能大，使之全程不发放脉冲，这相当于取消了最后一层的自回归结构。连接液态机与回归分类器，进行训练，训练过程中各项指标如下图所示：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07031936/reg_result.jpg)

​	上述结果是171条数据的训练所得，每5条数据进行一次统计，仅用一条数据作为测试集，因此测试集统计结果可忽略。训练集准确率虽有上升趋势，但损失几乎没有下降。

### 5. 现存问题

1. 模型过大：

​	液态机训练需要25.9G左右的显存，液态机+分类器训练需要50G左右的显存（这还是取消了液态机前馈中所有自循环结构的结果）。目前，液态机需要用RTX 3090训练，液态机+分类器需要用RTX A6000训练。计划在模型效果得到保证后，针对液态机作剪枝处理（因为按现用STDP规则，存在大量0突触）。

2. 最后一层LIF脉冲发放率过度离散化：

​	最后一层采用了500个神经元，但脉冲发放率分布相当离散，这说明最后一层内部，各神经元间差异极小，这很可能导致它无法携带有效信息，从而导致了不理想的分类结果。目前推测这很可能是模型过深所导致的。计划下一步减少模型层次。

### 6. 总结

​	虽然最终分类不理想，但一方面，代码成功跑通，已实现目的；另一方面，EEG通道的选取和脉冲编码都极为草率，使之注定是一个不可能成功的实验，因此不可谓失败。





## 2024年7月6日

### 1. 实验目的

​	验证下图所示液态机架构的滤波能力：

![double_structure](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/double_structure.png)

​	其中g为折扣因子，取0.5。

### 2. 放弃实验

​	考虑Linear(14, 20)，对于输出的20个神经元，每个都与14个输入全连接；而对于每个输出神经元所对应的这14个突触，均遵循着一样的初始化方法。因此，各神经元的输出理应趋同，并不能起到信息整合的作用。但我们不妨考虑下面的架构：

![unit](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/unit.png)

​	进行这样的设计的原因如下：

1. 存在自循环结构：上一次的脉冲输出将直接影响下一次的脉冲输出，而这使之具有更好的记忆能力。
2. 用Linear实现自循环，能将上一次的脉冲信息在所有神经元间共享：根据对前一个架构的反思，t时刻的LIF相对t-1时刻的LIF，是输出神经元，而神经元间的突触遵循相似的分布，这便在回馈脉冲的同时，整合了前一次脉冲的信息。同时，t时刻LIF的输出又受到t时刻EEG输入的影响，这又让神经元间存在特异性。

​	我同时思考了经典液态机架构为什么不存在我所面临的问题：经典液态机没有层结构，因此每个突触后神经元对应的突触连接模式有先天的差异。

​	这一新架构，本质上是一个时序压缩单元。若我们取最后一个时间步的s用于分类，实际是将n个时间步的输入压缩到了单时间步的s上。这时，s的形状与每个时间步x的形状均相同。按液态机理论，这并不能使数据更线性可分，但却取消了一个维度。在此之前，每个时间步的数据并不拥有相等的地位，对它们直接处理是困难的，而经这一单元压缩后，时间维度被取消，问题也就迎刃而解。





## 2024年7月7日

### 1. 实验目的

​	验证下图所示“时序压缩单元”架构。

![unit](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/SCU.png)

​	注：

1. 加法操作的具体内涵：对线性层，取两倍输出再除以神经元数量，将其结果与当前EEG输入相加。

```python
inp=inp+2*self.linear(self.cache)/self.channel_amount
```

2. LIF的设置：

```python
self.lif=neuron.LIFNode(tau=10.0, v_threshold=3.0, decay_input=False)
```

​	tau设得很大，会让LIF的渗漏速率变得很小；同时对总的输入电压不予衰减。

3. 取全部32个脑电通道。

### 2. 涉及文件

1. 时序压缩单元模型权重及训练参数： [STDP_model_07071250.tar.gz](model/STDP/EEG/STDP_model_07071250.tar.gz) 
2. 逻辑回归分类器权重及训练参数： [Reg_model_07071732.tar.gz](model/Regression/Reg_model_07071732.tar.gz) 
3. 源代码： [SNN_pkg_07071754.tar.gz](src_files/history/SNN_pkg_07071754.tar.gz) 

### 3. STDP训练指标

​	对任意数据，待全部时间步的张量全被输入后，才进行一次权重更新。经489条数据训练，$C_l$收敛至$10^{-5}$以下。训练过程中$C_l$变化如下所示：

![cl](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/cl.jpg)

$C_l$曲线异常标准。统计每条数据最后一个时间步诱发的脉冲发放率，其变化如下图所示：

![firing_rate](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/firing_rate.jpg)

最终脉冲发放率在0.2左右大幅震荡。“在0.2左右”意味着脉冲发放是稀疏的，“大幅震荡”说明该单元可能对EEG的特征敏感。对突触权重进行统计，3.12%的突触权重为0，其余为1，在具备差异性的同时起到了自循环效果。

​	随机选取三条数据，记录每个时间步的脉冲发放率，如下图:

![3_sample_test](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/3_sample_test.jpg)

### 4. 分类器训练指标

​	![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07071732/reg_result.jpg)

​	另从全部DEAP中选取128个数据进行测试，结果如下：

```
Test: loss=0.4074633717536926, accuracy=0.234375
```

​	与瞎蒙效果差不多。但相较上次回归训练，有两大突破：一，训练Loss不再离散化；二，测试集中Loss逐渐减小。

### 5. 反思总结

​	时序压缩单元的各项指标都很好，但分类效果不好，这很可能是分类器而非时序压缩单元的问题。而对分类器，当务之急的改进是对输入的Liquid state做中心化处理：

​	LIF的阈值为3，其重置电位为0，故任意神经元输出的Liquid state取值范围为$[1, e^3)$，因此对Liquid state 's'，做如下处理：
$$
s<=\frac{s-\frac{1+e^3}{2}}{\frac{e^3-1}{2}}=\frac{2s-(e^3+1)}{e^3-1}
$$
​	此外，对平台应做一点改进：使用SNN_pkg.tools.SimpleDeap().split()生成数据集后，应存储训练集和测试集索引。

​	加上中心化后，进行部分训练，得到结果如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/reg_result.jpg)

​	训练过程指标都有所改善。但在128条数据上做测试，准确率仍为25%左右。

​	随后我又做了两个重要调整：**改MSELoss为BCELoss（这才是逻辑回归真正需要的损失函数）、改SGD优化器为Adam**。训练过程中，将测试集的划分从原先的12条数据扩充到128条。训练过程如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07072210/reg_result.jpg)

​	训练完毕后，随机抽取640条数据作测试，得到结果如下：

```
Test: loss=0.6871862411499023, accuracy=0.325
```

​	可见推理正确对本模型不再是随机事件，这是一个巨大的突破，证明时序压缩单元有效地保留了脉冲序列的特征。

​	模型文件： [Reg_model_07072210.tar.gz](model/Regression/Reg_model_07072210.tar.gz) 

​	源代码文件： [SNN_pkg_07072214.tar.gz](src_files/history/SNN_pkg_07072214.tar.gz) 

​	下次考虑用DNN对Liquid State模式进行深入学习。





## 2024年7月17日

### 1. 主题

​	非脉冲形式EEG输入+DNN分类器。

### 2. 涉及文件

1. 源代码： [SNN_pkg_07171625.tar.gz](src_files/history/SNN_pkg_07171625.tar.gz) 
2. 模型文件： [Reg_model_07171622.tar.gz](model/Regression/Reg_model_07171622.tar.gz) 

### 3. 实验结果

​	对分类器，设置Adam学习率5e-4，训练集batch_size=8，进行两个epochs，得到结果如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07171622/reg_result.jpg)

从全部数据随机抽样640条测试，结果如下：

```bash
Test: loss=0.6793898940086365, accuracy=0.3546875
```

没有显著进展。





## 2024年7月28日

### 1. 关键词

​	带自连接及WTA的LSM+ZZH编码

​	STDP训练时取时间步长度为128\*6的ZZH编码数据；分类器取128\*30，batch_size=16。

### 2. 配置

​	LSM定义如下：

```python
class EEG_LSM(nn.Module):
    def __init__(self):
        super().__init__()
        self.b1_linear=layer.Linear(32,64,bias=False)
        self.b1_neuron=WTA_LIFNode(tau=80000., v_threshold=1.2, decay_input=False)
        self.b1_cache=0
        self.b2_linear=layer.Linear(64,128,bias=False)
        self.b2_neuron=WTA_LIFNode(tau=80000., v_threshold=1.2, decay_input=False)
        self.b2_cache=0
        self.b2_recurrent=layer.Linear(128,128,bias=False)
        self.b3_linear=layer.Linear(128,128,bias=False)
        self.b3_neuron=WTA_LIFNode(tau=80000., v_threshold=1.2, decay_input=False)
        self.b3_cache=0
        self.rates=[]  # Used to record the firing rates of each LIF layer while training.
        self.synapse_list=[
            [self.b1_linear, self.b1_neuron],
            [self.b2_linear, self.b2_neuron],
            [self.b2_recurrent, self.b2_neuron],
            [self.b3_linear, self.b3_neuron]
          ]
        for param in self.parameters():
            torch.nn.init.normal_(param.data, mean=0.8, std=0.05)
            param.data=torch.clamp(param.data, min=0, max=1)
    def __getitem__(self, index):
        return self.synapse_list[index]
    def __len__(self):
        return len(self.synapse_list)
    def forward(self, x, record_rate: bool = False, auto_reset: bool = True):
        '''
        x: shape [batch_size, 32, time_step]
        out: [batch_size, 500]
        '''
        batch_size,l,time_step=x.shape
        self.b1_cache=torch.zeros(batch_size,64)
        self.b2_cache=torch.zeros(batch_size,128)
        if torch.cuda.is_available()==True:
            self.b1_cache=self.b1_cache.cuda()
            self.b2_cache=self.b2_cache.cuda()
        if auto_reset==True:
            functional.reset_net(self)
        for i in range(time_step):
            inp=x[:,:,i]  # shape: [batch_size, 32]
            inp=self.b1_linear(inp)
            inp=self.b1_neuron(inp)
            self.b1_cache=inp
            inp=self.b2_linear(inp)
            y_cache=self.b2_recurrent(self.b2_cache)
            inp=self.b2_neuron(inp+y_cache)
            self.b2_cache=inp
            inp=self.b3_linear(inp)
            inp=self.b3_neuron(inp)
            self.b3_cache=inp
            if record_rate==True and i==time_step-1:
                # Then record the firing rates of each neuron layer.
                rate_list=[]
                n_1=self.b1_cache[0].detach()
                n_2=self.b2_cache[0].detach()
                n_3=self.b3_cache[0].detach()
                rate_list.append((n_1.sum()/len(n_1)).cpu().item())
                rate_list.append((n_2.sum()/len(n_2)).cpu().item())
                rate_list.append((n_3.sum()/len(n_3)).cpu().item())
                self.rates=rate_list
        liquid_state=torch.exp(self.b3_neuron.pre_v)
        return liquid_state

```

​	DNN分类器定义如下：

```python
class EEG_DNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear_1=nn.Linear(128,1000)
        self.batch_norm_1=nn.BatchNorm1d(1000)
        self.ReLU_1=nn.ReLU()
        self.linear_2=nn.Linear(1000,2)
        self.batch_norm_2=nn.BatchNorm1d(2)
        self.sigmoid=nn.Sigmoid()
    def forward(self, state):
        '''
        in: [batch_size, 32]
        out: [batch_size, 2]
        '''
        state=(2*state-(math.exp(3)+1))/(math.exp(3)-1)
        b1_state=self.linear_1(state)
        b1_state_after_linear=b1_state
        b1_state=self.batch_norm_1(b1_state)
        b1_state=self.ReLU_1(b1_state)
        b2_state=self.linear_2(b1_state)+b1_state_after_linear.abs().mean()
        b2_state=self.batch_norm_2(b2_state)
        pred=self.sigmoid(b2_state)
        return pred
```

​	STDP训练时数据取法：

```python
basic_data = pkg.tools.SimpleDeap(DEAP_dir, mode="zzh", memory_num=10, time=6)
train_data, valid_data, test_data = basic_data.split()
train_ds=torch.utils.data.DataLoader(train_data, batch_size=1)
test_ds=torch.utils.data.DataLoader(valid_data, batch_size=1)
```

​	分类器训练时数据取法：
```python
basic_data = pkg.tools.SimpleDeap(DEAP_dir, mode="zzh", memory_num=10, time = 30)
train_data, valid_data, test_data = basic_data.split()
train_ds=torch.utils.data.DataLoader(train_data, batch_size=16)
test_ds=torch.utils.data.DataLoader(valid_data, batch_size=32)
```

### 3. 重要文件

1. STDP模型文件： [STDP_model_07281534.tar.gz](model/STDP/EEG/STDP_model_07281534.tar.gz) 
2. DNN分类器模型文件： [Reg_model_07281930.tar.gz](model/Regression/Reg_model_07281930.tar.gz) 

### 4. 分类结果

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07281930/reg_result.jpg)





## 2024年7月28日

## 1. 关键词

​	用与同日ZZH编码数据对应模型相同的配置，利用BSA编码数据进行训练，以对比两种编码在LSM架构下的优劣。

### 2. 重要文件

STDP模型文件： [STDP_model_07281934.tar.gz](../../tmp/STDP_model_07281934.tar.gz) 

DNN分类器文件： [Reg_model_07282159.tar.gz](model/Regression/Reg_model_07282159.tar.gz) 

设置mean=0.7, std=0.15时，BSA分类器文件： [Reg_model_07282326.tar.gz](model/Regression/Reg_model_07282326.tar.gz) 

### 3. 实验结果

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07282159/reg_result.jpg)

完全按前述参数实验，STDP训练期间权重几乎不变。分类器训练时，测试准确率、Loss波动极大，最后在%40左右浮动。

修改初始化权重，设置mean=0.7, std=0.15，结果明显好转：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07282326/reg_result.jpg)

下一步继续增大标准差，看看有没有更好的效果。





## 2024年7月29日

### 1. 主题

	1. 针对BSA编码，进一步扩大初始化权重标准差，看测试准确率是否进一步提升。
	1. 取STDP训练不同阶段的LSM训练分类器，验证STDP的促进作用。

### 2. 初始化配置

```python
for param in self.parameters():
	torch.nn.init.normal_(param.data, mean=0.65, std=0.3)
	param.data=torch.clamp(param.data, min=0, max=1)
```

LSM和DNN其它配置如7月28日第一次实验所述。

### 3. 重要文件

嵌套几乎未经STDP训练的DNN模型： [Reg_model_07290903.tar.gz](model/Regression/Reg_model_07290903.tar.gz) 

嵌套经过约3500次STDP优化的DNN： [Reg_model_07291444.tar.gz](model/Regression/Reg_model_07291444.tar.gz) 

嵌套经过约5500次STDP优化的DNN： [Reg_model_07291859.tar.gz](model/Regression/Reg_model_07291859.tar.gz) 

嵌套经过约5500次STDP优化的DNN（改截10秒一段送入分类器训练）： [Reg_model_07301023.tar.gz](model/Regression/Reg_model_07301023.tar.gz) 

### 4. 实验结果

未经STDP训练时，分类器训练情况如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07290903/reg_result.jpg)

经3500次STDP优化：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07291444/reg_result.jpg)

经5500次STDP优化：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07291859/reg_result.jpg)

用相同的压缩单元，改截10秒一段训练分类器，结果如下：![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07301023/reg_result.jpg)
