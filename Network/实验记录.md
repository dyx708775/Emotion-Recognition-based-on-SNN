# 实验记录



## 2024年7月3日

### 1. 关键词

​	EEG时间序列建模、自回归层结构液态机

### 2. 归档文件

1. 源代码： [SNN_pkg_07031834.tar.gz](src_files/history/SNN_pkg_07031834.tar.gz)
2. STDP液态机模型及实验数据： [STDP_model_07031659.tar.gz](model/STDP/EEG/STDP_model_07031659.tar.gz) 
3. 回归分类器及实验数据： [Reg_model_07031936.tar.gz](model/Regression/Reg_model_07031936.tar.gz) 

### 3. 实验目的

​	完成StdpModel.py和Regression.py代码的修正，保证其正常工作，初步研究当前架构是否有特征提取能力。

### 4. 实验结果

​	STDP及Regression两部分代码已全部跑通。

​	编码上，对DEAP脑电数据集取前14个通道（未必是适用于情感计算的通道），并以0为界，编码为脉冲序列。液态机方面，按原先设计，设置三个自连接突触，导致训练时三个LIF层神经元脉冲发放率均为100%；遂去掉前两层的自回归突触，保留第三层，成功使脉冲发放稀疏化。经59条相互独立的数据处理后，各层$C_l$值收敛至$10^{-5}$以下。

​	训练过程中，$C_l$值变化如下图：

![cl](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/cl.jpg)

​	脉冲发放率变化如下图（仅对一条数据最后一个时间步所诱发的脉冲发放进行采样）：

![firing_rate](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/firing_rate.jpg)

​	随机选取三条相互独立的数据，记录每个时间步所诱发的脉冲发放率。时间步7800后，脉冲发放率变化如下图所示：

![3_sample_test](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07031659/3_sample_test.jpg)

​	可以看到，数据间脉冲发放有较大差异性，这说明该液态机可能实现了特征提取。

​	但问题在于，由训练期间脉冲发放率变化图所示，每条数据最后一个时间步都会导致最后一层脉冲发放。因此，在回归时，改设最后一层LIF的阈值尽可能大，使之全程不发放脉冲，这相当于取消了最后一层的自回归结构。连接液态机与回归分类器，进行训练，训练过程中各项指标如下图所示：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07031936/reg_result.jpg)

​	上述结果是171条数据的训练所得，每5条数据进行一次统计，仅用一条数据作为测试集，因此测试集统计结果可忽略。训练集准确率虽有上升趋势，但损失几乎没有下降。

### 5. 现存问题

1. 模型过大：

​	液态机训练需要25.9G左右的显存，液态机+分类器训练需要50G左右的显存（这还是取消了液态机前馈中所有自循环结构的结果）。目前，液态机需要用RTX 3090训练，液态机+分类器需要用RTX A6000训练。计划在模型效果得到保证后，针对液态机作剪枝处理（因为按现用STDP规则，存在大量0突触）。

2. 最后一层LIF脉冲发放率过度离散化：

​	最后一层采用了500个神经元，但脉冲发放率分布相当离散，这说明最后一层内部，各神经元间差异极小，这很可能导致它无法携带有效信息，从而导致了不理想的分类结果。目前推测这很可能是模型过深所导致的。计划下一步减少模型层次。

### 6. 总结

​	虽然最终分类不理想，但一方面，代码成功跑通，已实现目的；另一方面，EEG通道的选取和脉冲编码都极为草率，使之注定是一个不可能成功的实验，因此不可谓失败。





## 2024年7月6日

### 1. 实验目的

​	验证下图所示液态机架构的滤波能力：

![double_structure](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/double_structure.png)

​	其中g为折扣因子，取0.5。

### 2. 放弃实验

​	考虑Linear(14, 20)，对于输出的20个神经元，每个都与14个输入全连接；而对于每个输出神经元所对应的这14个突触，均遵循着一样的初始化方法。因此，各神经元的输出理应趋同，并不能起到信息整合的作用。但我们不妨考虑下面的架构：

![unit](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/unit.png)

​	进行这样的设计的原因如下：

1. 存在自循环结构：上一次的脉冲输出将直接影响下一次的脉冲输出，而这使之具有更好的记忆能力。
2. 用Linear实现自循环，能将上一次的脉冲信息在所有神经元间共享：根据对前一个架构的反思，t时刻的LIF相对t-1时刻的LIF，是输出神经元，而神经元间的突触遵循相似的分布，这便在回馈脉冲的同时，整合了前一次脉冲的信息。同时，t时刻LIF的输出又受到t时刻EEG输入的影响，这又让神经元间存在特异性。

​	我同时思考了经典液态机架构为什么不存在我所面临的问题：经典液态机没有层结构，因此每个突触后神经元对应的突触连接模式有先天的差异。

​	这一新架构，本质上是一个时序压缩单元。若我们取最后一个时间步的s用于分类，实际是将n个时间步的输入压缩到了单时间步的s上。这时，s的形状与每个时间步x的形状均相同。按液态机理论，这并不能使数据更线性可分，但却取消了一个维度。在此之前，每个时间步的数据并不拥有相等的地位，对它们直接处理是困难的，而经这一单元压缩后，时间维度被取消，问题也就迎刃而解。





## 2024年7月7日

### 1. 实验目的

​	验证下图所示“时序压缩单元”架构。

![unit](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/SCU.png)

​	注：

1. 加法操作的具体内涵：对线性层，取两倍输出再除以神经元数量，将其结果与当前EEG输入相加。

```python
inp=inp+2*self.linear(self.cache)/self.channel_amount
```

2. LIF的设置：

```python
self.lif=neuron.LIFNode(tau=10.0, v_threshold=3.0, decay_input=False)
```

​	tau设得很大，会让LIF的渗漏速率变得很小；同时对总的输入电压不予衰减。

3. 取全部32个脑电通道。

### 2. 涉及文件

1. 时序压缩单元模型权重及训练参数： [STDP_model_07071250.tar.gz](model/STDP/EEG/STDP_model_07071250.tar.gz) 
2. 逻辑回归分类器权重及训练参数： [Reg_model_07071732.tar.gz](model/Regression/Reg_model_07071732.tar.gz) 
3. 源代码： [SNN_pkg_07071754.tar.gz](src_files/history/SNN_pkg_07071754.tar.gz) 

### 3. STDP训练指标

​	对任意数据，待全部时间步的张量全被输入后，才进行一次权重更新。经489条数据训练，$C_l$收敛至$10^{-5}$以下。训练过程中$C_l$变化如下所示：

![cl](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/cl.jpg)

$C_l$曲线异常标准。统计每条数据最后一个时间步诱发的脉冲发放率，其变化如下图所示：

![firing_rate](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/firing_rate.jpg)

最终脉冲发放率在0.2左右大幅震荡。“在0.2左右”意味着脉冲发放是稀疏的，“大幅震荡”说明该单元可能对EEG的特征敏感。对突触权重进行统计，3.12%的突触权重为0，其余为1，在具备差异性的同时起到了自循环效果。

​	随机选取三条数据，记录每个时间步的脉冲发放率，如下图:

![3_sample_test](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/STDP/EEG/STDP_model_07071250/3_sample_test.jpg)

### 4. 分类器训练指标

​	![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07071732/reg_result.jpg)

​	另从全部DEAP中选取128个数据进行测试，结果如下：

```
Test: loss=0.4074633717536926, accuracy=0.234375
```

​	与瞎蒙效果差不多。但相较上次回归训练，有两大突破：一，训练Loss不再离散化；二，测试集中Loss逐渐减小。

### 5. 反思总结

​	时序压缩单元的各项指标都很好，但分类效果不好，这很可能是分类器而非时序压缩单元的问题。而对分类器，当务之急的改进是对输入的Liquid state做中心化处理：

​	LIF的阈值为3，其重置电位为0，故任意神经元输出的Liquid state取值范围为$[1, e^3)$，因此对Liquid state 's'，做如下处理：
$$
s<=\frac{s-\frac{1+e^3}{2}}{\frac{e^3-1}{2}}=\frac{2s-(e^3+1)}{e^3-1}
$$
​	此外，对平台应做一点改进：使用SNN_pkg.tools.SimpleDeap().split()生成数据集后，应存储训练集和测试集索引。

​	加上中心化后，进行部分训练，得到结果如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/description/reg_result.jpg)

​	训练过程指标都有所改善。但在128条数据上做测试，准确率仍为25%左右。

​	随后我又做了两个重要调整：**改MSELoss为BCELoss（这才是逻辑回归真正需要的损失函数）、改SGD优化器为Adam**。训练过程中，将测试集的划分从原先的12条数据扩充到128条。训练过程如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07072210/reg_result.jpg)

​	训练完毕后，随机抽取640条数据作测试，得到结果如下：

```
Test: loss=0.6871862411499023, accuracy=0.325
```

​	可见推理正确对本模型不再是随机事件，这是一个巨大的突破，证明时序压缩单元有效地保留了脉冲序列的特征。

​	模型文件： [Reg_model_07072210.tar.gz](model/Regression/Reg_model_07072210.tar.gz) 

​	源代码文件： [SNN_pkg_07072214.tar.gz](src_files/history/SNN_pkg_07072214.tar.gz) 

​	下次考虑用DNN对Liquid State模式进行深入学习。





## 2024年7月17日

### 1. 主题

​	非脉冲形式EEG输入+DNN分类器。

### 2. 涉及文件

1. 源代码： [SNN_pkg_07171625.tar.gz](src_files/history/SNN_pkg_07171625.tar.gz) 
2. 模型文件： [Reg_model_07171622.tar.gz](model/Regression/Reg_model_07171622.tar.gz) 

### 3. 实验结果

​	对分类器，设置Adam学习率5e-4，训练集batch_size=8，进行两个epochs，得到结果如下图：

![reg_result](/home/xiangnan/Files/code/SNN/Emotion-Recognition-based-on-SNN/Network/model/Regression/Reg_model_07171622/reg_result.jpg)

从全部数据随机抽样640条测试，结果如下：

```bash
Test: loss=0.6793898940086365, accuracy=0.3546875
```

没有显著进展。
